{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('assignment/loan_data_set.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna_mapping = {\n",
    "    'LoanAmount': df['LoanAmount'].mean(skipna=True),\n",
    "    'Gender': df['Gender'].mode(dropna=True).iloc[0],\n",
    "    'Married': df['Married'].mode(dropna=True).iloc[0],\n",
    "    'Dependents': df['Dependents'].mode(dropna=True).iloc[0],\n",
    "    'Education': df['Education'].mode(dropna=True).iloc[0],\n",
    "    'Self_Employed': df['Self_Employed'].mode(dropna=True).iloc[0],\n",
    "    'ApplicantIncome': df['ApplicantIncome'].mode(dropna=True).iloc[0],\n",
    "    'CoapplicantIncome': df['CoapplicantIncome'].mode(dropna=True).iloc[0],\n",
    "    'Credit_History': df['Credit_History'].mode(dropna=True).iloc[0],\n",
    "    'Loan_Amount_Term': df['Loan_Amount_Term'].mode(dropna=True).iloc[0],\n",
    "}\n",
    "df.fillna(fillna_mapping, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'Male': 0,\n",
    "    'Female': 1,\n",
    "    'No': 0,\n",
    "    'Yes': 1,\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3+': 3,\n",
    "    'Not Graduate': 0,\n",
    "    'Graduate': 1,\n",
    "    'N': 0,\n",
    "    'Y': 1,\n",
    "}\n",
    "df.replace(label_mapping, inplace=True)\n",
    "# cast ApplicantIncome column to float\n",
    "df['ApplicantIncome'] = df['ApplicantIncome'].astype(float)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Loan_ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Loan_ID', axis='columns', inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model Input/Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input column\n",
    "X = df[['Gender',\n",
    " 'Married',\n",
    " 'Dependents',\n",
    " 'Education',\n",
    " 'Self_Employed',\n",
    " 'ApplicantIncome',\n",
    " 'CoapplicantIncome',\n",
    " 'LoanAmount',\n",
    " 'Loan_Amount_Term',\n",
    " 'Credit_History'] ]\n",
    "Y = df['Loan_Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "Y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X, Y = sm.fit_resample(X, Y)\n",
    "Y.value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "Y.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train.info()\n",
    "X_test.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, \\\n",
    "    roc_auc_score, RocCurveDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def evaluate_model(Y_true, Y_pred, Y_pred_proba):\n",
    "    # confusion matrix\n",
    "    cf_matrix = confusion_matrix(Y_pred, Y_true, labels=[0,1])\n",
    "    sns.heatmap(cf_matrix, annot=True)\n",
    "    # Accuracy Score\n",
    "    print ('Accuracy Score :{:.2f}'.format(accuracy_score(Y_pred, Y_true)*100))\n",
    "    # Precision Score\n",
    "    print ('Precision Score :{:.2f}'.format(precision_score(Y_pred, Y_true, pos_label=0)*100))\n",
    "    # Recall Score\n",
    "    print ('Recall Score :{:.2f}'.format(recall_score(Y_pred, Y_true, pos_label=0)*100))\n",
    "    # F1 Score\n",
    "    print ('F1 Score :{:.2f}'.format(f1_score(Y_pred, Y_true, pos_label=0)*100))\n",
    "    # AUC Score\n",
    "    print('AUC: {:.2f}'.format(roc_auc_score(Y_true, Y_pred_proba[:, 1])*100))\n",
    "    # plot ROC curve\n",
    "    RocCurveDisplay.from_predictions(Y_true, Y_pred_proba[:, 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, modelname):\n",
    "    with open(f\"models/{modelname}\", 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def predict_result(inputvector, modelname):\n",
    "    with open(f\"models/{modelname}\", 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model.predict([inputvector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "# train model\n",
    "lr_model.fit(X_train , Y_train)\n",
    "# predict on test split\n",
    "Y_pred_lr = lr_model.predict(X_test)\n",
    "Y_pred_lr_proba = lr_model.predict_proba(X_test)\n",
    "# evaluate model\n",
    "evaluate_model(Y_test, Y_pred_lr, Y_pred_lr_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(lr_model, 'logistic_regression')\n",
    "predict_result([0,1,2,1,0,4006,1526,168,360,1], 'logistic_regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "# train model\n",
    "dt_model.fit(X_train , Y_train)\n",
    "# predict on test split\n",
    "Y_pred_dt = dt_model.predict(X_test)\n",
    "Y_pred_dt_proba = dt_model.predict_proba(X_test)\n",
    "# evaluate model\n",
    "evaluate_model(Y_test, Y_pred_dt, Y_pred_dt_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(dt_model, 'decision_trees')\n",
    "predict_result([0,1,2,1,0,4006,1526,168,360,1], 'decision_trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "bayes_model = CategoricalNB(alpha=0)\n",
    "# train model\n",
    "bayes_model.fit(X_train , Y_train)\n",
    "# predict on test split\n",
    "Y_pred_bayes = bayes_model.predict(X_test)\n",
    "Y_pred_bayes_proba = bayes_model.predict_proba(X_test)\n",
    "# evaluate model\n",
    "evaluate_model(Y_test, Y_pred_bayes, Y_pred_bayes_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(bayes_model, 'bayes')\n",
    "predict_result([0,1,2,1,0,4006,1526,168,360,1], 'bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "# train model\n",
    "knn_model.fit(X_train , Y_train)\n",
    "# predict on test split\n",
    "Y_pred_knn = knn_model.predict(X_test)\n",
    "Y_pred_knn_proba = knn_model.predict_proba(X_test)\n",
    "# evaluate model\n",
    "evaluate_model(Y_test, Y_pred_knn, Y_pred_knn_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(knn_model, 'knn')\n",
    "predict_result([0,1,2,1,0,4006,1526,168,360,1], 'knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "# train model\n",
    "svm_model.fit(X_train , Y_train)\n",
    "# predict on test split\n",
    "Y_pred_svm = svm_model.predict(X_test)\n",
    "Y_pred_svm_proba = svm_model.predict_proba(X_test)\n",
    "# evaluate model\n",
    "evaluate_model(Y_test, Y_pred_svm, Y_pred_svm_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(svm_model, 'svm')\n",
    "predict_result([0,1,2,1,0,4006,1526,168,360,1], 'svm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc7f257c0b8adbd0b56b4d474c1123b1833bb59202044f69f8b30c2e4e8e71e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
